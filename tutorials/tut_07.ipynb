{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tutorial 7 - Photometric redshifts.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will try to builds models to predict galaxy redshifts from their photometry in 5 bands.\n",
    "\n",
    "We will get some practice with the scikit-learn package which contains powerful tools for simple machine learning problems. (https://scikit-learn.org/stable/user_guide.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Import the data from the file reduced_galaxy_data.fits.  This file contains a small subset of data from the Slone Digital Sky Survey (SDSS).  The columns in the fits table are: id number, the measured spectroscopic redshift, the fluxes in five bands (ugriz), and the magnitudes in the same five bands.  Note that the entry in the flux and magnitude columns is an array of 5 entries.\n",
    "\n",
    "Put the redshifts into an array called `redshift` and the magnitudes into a two dimensional array `color_block` where `color_block[0]` are the 5 magnitudes for the first entry.\n",
    "\n",
    "Make a scatter plot of redshift versus u band magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "#import pandas as pa\n",
    "\n",
    "filename = \"reduced_galaxy_data.fits\"\n",
    "hdul = fits.open(filename)\n",
    "print(hdul[1].columns)\n",
    "data = hdul[1].data\n",
    "\n",
    "redshift = np.array(data['z'])\n",
    "\n",
    "....\n",
    "\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('U magnitude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Subtract the U band magnitude from all the other bands so that we have 4 colors and one apparent magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in np.arange(1,5) :\n",
    "    color_block[:,i] = color_block[:,i] - color_block[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) From sklearn import `linear_model`.  Make a `linear_model.LinearRegression(copy_X=True)` object \n",
    "and then fit a model that predicts redshifts from the colors and the U band magnitude. (see https://scikit-learn.org/stable/modules/linear_model.html for more information.)  Print out the coefficients.  Use the model.score() function to give the score for the model which in this case is the R^2 statistic (coefficient of determination)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "linear_mod = ...\n",
    "linear_mod.fit(...)\n",
    "\n",
    "print('coefficients : ',...)\n",
    "print(\"score = \",linear_mod.score(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Use the model to predict the redshifts for all of the galaxies.  Make a scatter plot of the predicted vs observed redshifts. Decreasing the alpha parameter can make this clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict redshifts\n",
    "y = linear_mod ...\n",
    "\n",
    "# plot prediction vs redshifts\n",
    "\n",
    "plt.scatter(y,redshift,alpha=0.05)\n",
    "plt.plot([0,5],[0,5],linestyle=':')\n",
    "plt.ylabel(\"observed\")\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.xlim(0,0.5)\n",
    "plt.ylim(0,0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Scatter plots can be deceiving.  The density of points can be estimated with a Gaussian kernel.  This should do that.  Put some labels on the plot and overlay a contour plot.  (If you can make a nicer countour plot than this extra point.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kde\n",
    "\n",
    "nbins = 40\n",
    "#k = kde.gaussian_kde(np.array([predictions,observations]))\n",
    "k = kde.gaussian_kde(np.array([ ... , ... ]))\n",
    "\n",
    "xi, yi = np.mgrid[0:0.5:nbins*1j, 0:0.5:nbins*1j]\n",
    "zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    " \n",
    "plt.pcolormesh(xi,yi, zi.reshape(xi.shape), shading='gouraud')\n",
    "plt.plot([0,0.5],[0,0.5],linestyle=':')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) We are going to need a quick way of assessing how well a model is working.\n",
    "\n",
    "Make a function that takes the residuals (predictions - true values) and prints six things : 1) their median, 2) mean, 3) the range the contains 90% of the cases with 5% larger and smaller, 4) the same for 80%, 5) the standard deviation and 6) the mean absolute deviation.  \n",
    "\n",
    "Call this function `report()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(residuals) :\n",
    "    print('median',...)\n",
    "    print('mean',...)\n",
    "    print('90% quantile range : ',... , ...)\n",
    "    print('80% quantile range : ', ... , ...)\n",
    "    print('standard deviation : ', ... )\n",
    "    print('mean absolute deviation : ', ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) We need a quick way of calculating the residuals, but we cannot calculate the residuals on the same data as we fit the model.  Let's make a function the splits the data in two, fits on one subset and calculates the residuals on the remaining subset.\n",
    "\n",
    "The function should take the independent variables `X`, the dependent variable `Y`, the model `model` and the fraction of the data set that will be used for fitting the the model.  The `model` has the functions `fit()` and `predict()` as for the sklearn models.  The function should split the data set into two random subsets: fit and test.  It should then fit the model and then return the residuals for the test set and the true Y values of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_residuals(X,Y,model,fit_fraction) :\n",
    "   \n",
    "    # make and index\n",
    "    ...\n",
    "    # shuffle the index\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    #split the index into two parts \n",
    "    \n",
    "    split = int(fit_fraction*N)\n",
    "    index_fit = index[:split]\n",
    "    index_test = ...\n",
    "\n",
    "    # define X_fit,Y_fit\n",
    "    X_fit = ...\n",
    "    Y_fit = ...\n",
    "\n",
    "    # define X_test, Y_test\n",
    " \n",
    "    X_test = ...\n",
    "    Y_test = ...\n",
    "\n",
    "    ## fit model\n",
    "   \n",
    "    ## predict redshifts\n",
    "   \n",
    "    return ... , ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Use your function `test_residuals()` to get a set of residuals with `linear_mod` and our data.  Use 80% of the data for fitting and 20% for testing. Run `report()` on the resulting residuals to see how well this model predicts the redshifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Make a nice histogram of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals,z_test = test_residuals(color_block, ... ,... ,...)\n",
    "\n",
    "print(\"residuals\")\n",
    "report(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) What is important is that the fractional error in the redshift is small, i.e. `residuals / y`.  Find the fractional residuals, run them through `report()` and make a histogram of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frac_residuals = ...\n",
    "\n",
    "print(\"fractional residuals\")\n",
    "report(frac_residuals)\n",
    "\n",
    "plt.hist(...)\n",
    "plt.xlabel(...)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Would you consider this a successful model in terms of the fractional residuals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) So far, the model has been linear in the parameters AND the colors/magnitude.  It might improve the model if we include terms in the model that are second order in the colors while keeping it linear in the parameters.\n",
    "\n",
    "`sklearn` provides a convenient function that will transform our matrix of colors into a larger matrix that includes higher order terms.  In particular, `PolynomialFeatures(2).fit_transform(color_block)` will include all the colors squared and all the products of the colors.\n",
    "\n",
    "Use this function to transform our `color_block` into another one with second order terms.\n",
    "\n",
    "How many more parameters will be in a linear model fit with this new data matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import ...\n",
    "\n",
    "color_block2 = \n",
    "\n",
    "print(color_block2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Create and fit a new linear model using this new data matrix.\n",
    "\n",
    "What is the score for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inear_mod2 = ...\n",
    "linear_mod2 ...\n",
    "\n",
    "print(\"score = \",...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Use your functions `test_residuals()` and `report()` with this new model as before.  Make a histogram of the residuals as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals,z_test = ...\n",
    "\n",
    "print(\"residuals\")\n",
    "report(residuals)\n",
    "\n",
    "plt.hist(residuals,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) As before, do the same for the fractional residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16) Make a new contour plot for predictions based on `color_block2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17) Uses `sklearn.model_selection.cross_val_score` to find an estimate of the mean absolute error using k-fold validation. (scoring=\"neg_mean_absolute_error\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(..., ..., ..., cv=...,scoring=\"neg_mean_absolute_error\")\n",
    "print(-scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18) Is this model an improvement on the first one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
