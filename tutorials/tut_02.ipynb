{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2 - Covariance and Principle Components\n",
    "\n",
    "In this tutorial we will get some experience with estimating the covariance matrix and finding principle components of some data. You will also get some experience manipulating matrices in python.\n",
    "\n",
    "An estimator for the covariance matrix between variables $x$ and $y$ is\n",
    "\\begin{align}\n",
    "{\\hat{C}}_{xy} = \\frac{1}{N-1} \\sum_{i=1}^N \\left( x_i - \\bar{x} \\right) \\left( y_i - \\bar{y} \\right)\n",
    "\\end{align}\n",
    "where\n",
    "\\begin{align}\n",
    "\\bar{x} = \\frac{1}{N} \\sum_{i=1}^N x_i\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to import numpy, matplotlib.pyplot and pandas\n",
    "\n",
    "\n",
    "1) Read file homework_01_2d-datafile.csv into a dataframe using pandas\n",
    "\n",
    "Make a scatter plot of X vs Y.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2) Find the covariance matrix for the two variables.  Don't use the \n",
    " function numpy.cov(), write your own function this first time.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the covariance matrix C for X and Y.\n",
    "\n",
    "# Do X and Y appear to be correlated?\n",
    "\n",
    "# What is the variance of X?\n",
    "\n",
    "# What is the variance of Y?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Find the percision matrix and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalized covariance coefficients are\n",
    "\\begin{align}\n",
    "\\rho_{ij} = \\frac{\\hat{C}_{ij} }{\\sqrt{\\hat{C}_{ii} \\hat{C}_{jj} }}\n",
    "\\end{align}\n",
    "\n",
    "If the off-diagonal components of this matrix are measures of correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 4) Consider the following code:\n",
    " \n",
    "    D = np.diag(C)\n",
    "    \n",
    "    print D\n",
    "    \n",
    "    M =  np.outer(D,D)\n",
    "    \n",
    "    print M\n",
    "\n",
    " Use it to efficiently calculate the normalized covariance matrix and print it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 5) Decompose the covariance (not normalized) matrix using \n",
    "    an eigenvalue decompositions.\n",
    "    \n",
    "    Use w,v = numpy.linalg.eig() to find the decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # What are the principle components (eigenvectors) of the data? \n",
    "\n",
    "\n",
    "    # What are the eigenvalues?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 6) Transform the data into the basis of the principle components (or eigenvectors) that were found in 5).\n",
    "\n",
    "  You can collect the data into a structure data = np.array([X,Y]) and then matrix \n",
    "  multiply it by a matrix with @ (or np.dot(,) ). You might need to transpose something...\n",
    "  \n",
    "numpy.shape() is useful to make sure your doing matrix multiplications correctly.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make a scatter plot of the data in this basis\n",
    "\n",
    "#print the covariance matrix of the data in this basis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the diagonal elements (variances) of the covariance matrix \n",
    "to the eigenvalues you got in part 4).  Are the variances of the principle components larger, smaller or both \n",
    "larger and smaller than the original variances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 7) Do 1) through 6), but using the data file homework_01_5d-datafile.csv this time.\n",
    "    In this case the data is 5 dimensional.  You can use numpy.cov() this time.\n",
    "    You can't plot all those dimensions so you don't have to do the scatter plots\n",
    "    ,but feel free to plot some dimensions to make sure you are getting what \n",
    "    you expect.\n",
    "\n",
    " The best way to find the covariance matrix is to make a 5 by 2000 array out \n",
    " of the columns of the dataframe using numpy.array([...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Which variables seem to be correlated with each other and which ones not?\n",
    " \n",
    "\n",
    "    # What are the principle components (eigenvectors) of the data? \n",
    "\n",
    "\n",
    "    # What are the variances along each principle component?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
