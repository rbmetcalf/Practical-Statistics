{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2 - Covariance and Principle Components\n",
    "\n",
    "In this tutorial we will get some experience with estimating the covariance matrix and finding principle components of some data. You will also get some experience manipulating matrices in python.\n",
    "\n",
    "An estimator for the covariance matrix between variables $x$ and $y$ is\n",
    "\\begin{align}\n",
    "{\\hat{C}}_{xy} = \\frac{1}{N-1} \\sum_{i=1}^N \\left( x_i - \\bar{x} \\right) \\left( y_i - \\bar{y} \\right)\n",
    "\\end{align}\n",
    "where\n",
    "\\begin{align}\n",
    "\\bar{x} = \\frac{1}{N} \\sum_{i=1}^N x_i\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to import numpy, matplotlib.pyplot and pandas\n",
    "\n",
    "\n",
    "1) Read file `homework_01_2d-datafile.csv` into a dataframe using pandas\n",
    "\n",
    "Make a scatter plot of X vs Y.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2) Find the covariance matrix for the two variables.  Don't use the \n",
    " function numpy.cov(), write your own function this first time.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "C[0,0] = ...\n",
    "C[1,0] = ...\n",
    "C[0,1] = ...\n",
    "C[1,1] = ...\n",
    "\n",
    "# Print the covariance matrix C for X and Y.\n",
    "\n",
    "# Do X and Y appear to be correlated?\n",
    "\n",
    "# What is the variance of X?\n",
    "\n",
    "# What is the variance of Y?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Find the precision matrix, $C^{-1}$, and print it. (Use `np.linalg.inv()`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalized covariance coefficients, or Pearson's correlation coefficients,  are\n",
    "\\begin{align}\n",
    "\\rho_{ij} = \\frac{\\hat{C}_{ij} }{\\sqrt{\\hat{C}_{ii} \\hat{C}_{jj} }}\n",
    "\\end{align}\n",
    "\n",
    "The off-diagonal components of this matrix are measures of correlations.  They have a range of -1 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 4) Consider the following code:\n",
    " \n",
    " ```\n",
    "    D = np.diag(C)\n",
    "    \n",
    "    print(D)\n",
    "    \n",
    "    J =  np.outer(D,D)\n",
    "    \n",
    "    print(J)\n",
    "```\n",
    " Use it to efficiently calculate the denominator for the normalized covariance matrix and print the matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 5) Decompose the covariance (not normalized) matrix using \n",
    "    an eigenvalue decompositions.\n",
    "    \n",
    "    Use V,M = numpy.linalg.eig() to find the decomposition.  V contains the eigenvalues and M contains the eigenvectors as columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    ".\n",
    ".\n",
    ".\n",
    "    # What are the principle components (eigenvectors) of the data? \n",
    " .\n",
    " .\n",
    " .   \n",
    "    print(\"v1 = \",...)\n",
    "    print(\"v2 = \",...)\n",
    "\n",
    "\n",
    "    # What are the eigenvalues?\n",
    ".\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 6) Transform the data into the basis of the principle components (or eigenvectors) that were found in 5).  If `M` is a matrix whose *rows* are the eigenvectors of `C` then `x=M d` is the tranformation of the data point `d` into its principle components `x`.\n",
    "\n",
    "  You can collect the data into a structure `data = np.array([X,Y]`) and then matrix \n",
    "  multiply it by a matrix with `np.dot(,)` (or `@`). You might need to transpose something...\n",
    "  \n",
    "`numpy.shape()` is useful to make sure your doing matrix multiplications correctly when the matrices are not square.  The trick here is to remember what dimensions things should be.  This should take only a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make a scatter plot of the data in this basis\n",
    "\n",
    "#print the covariance matrix of the data in this basis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Compare the diagonal elements (variances) of the covariance matrix \n",
    "to the eigenvalues you got in part 4).  Are the variances of the principle components larger, smaller or both \n",
    "larger and smaller than the original variances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 8) Do 1) through 6), but using the data file `homework_01_5d-datafile.csv` this time.\n",
    "    In this case the data is 5 dimensional.  You can use numpy.cov() this time.\n",
    "    You can't plot all those dimensions so you don't have to do the scatter plots\n",
    "    ,but you can plat pairs of them.\n",
    "\n",
    " The best way to find the covariance matrix is to make a 5 by 2000 array out \n",
    " of the columns of the dataframe using `numpy.array([...])` as we did in the 2D case above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # read in the data into a dataframe\n",
    "    \n",
    "df = ...\n",
    "\n",
    "#print(df.info())\n",
    "\n",
    "# put the data into a 5 x 2000 numpy array\n",
    "\n",
    "data = ...\n",
    "np.shape(data)\n",
    "\n",
    "# find the covariance matrix of the data\n",
    "\n",
    "...\n",
    "\n",
    "print(C)\n",
    "\n",
    "# Which variables seem to be correlated with each other and which ones not?\n",
    "# Find this with the Person correlation coefficients.\n",
    "\n",
    "...\n",
    "\n",
    "print('R = ',R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Find the principle components and their variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # What are the principle components (eigenvectors) of the data? \n",
    "\n",
    "....\n",
    "\n",
    "    # What are the variances of each principle component?\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Make a copy (`data2`) of the `data` transformed into the PCA basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) This is a function that will make a scatter plot of all pairs of parameters int a triangle of panels.  Fill in the missing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def triangle_plot(data,labels=None):\n",
    "    n = data.shape[0]\n",
    "    fig, ax = plt.subplots(n-1,n-1)\n",
    "    \n",
    "    if(labels == None) :\n",
    "        labels = [ 'X'+str(i) for i in range(n)]\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        for j in range(i) :\n",
    "            ax[i,j].axis('off')\n",
    "        for j in range(i+1,n):\n",
    "            ax[i,j-1].scatter(...,...,s=0.2)\n",
    "            min = np.min([np.min(data[i,:]),np.min(data[j,:])])\n",
    "            max = np.max([np.max(data[i,:]),np.max(data[j,:])])\n",
    "            delt = (max - min)*0.1\n",
    "            ax[i,j-1].set_xlim(min-delt,max+delt)\n",
    "            ax[i,j-1].set_ylim(min-delt,max+delt)\n",
    "            if(i == j-1) :\n",
    "                ax[i,j-1].set_xlabel(labels[j],fontsize=8)\n",
    "                ax[i,j-1].set_ylabel(labels[i],fontsize=8)\n",
    "            else :\n",
    "                ax[i,j-1].tick_params(axis='both', which='both', labelsize=10)\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Use `triangle_plot()` to plot `data2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
