{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tutorial 6b - Microlensing event statistics: selection**\n",
    "\n",
    "In this tutorial, we will look at some gravitational microlensing data.  This is where a star is magnified by the presence of some compact massive object very close to the line of sight to the star.  Each microlensing event is detected by a brightening of a star in the galactic bulge, LMC or SMC.   From the light curve of the star during the event, three things can be measured - the time it occurs, the duration of the event, $\\Delta t$, and the Einstein crossing time, $t_E$.  $\\Delta t$ is defined as the length of time the star is magnified by greater than 1.34, which is the magnification the source will have when its angular separation from the lens is less than one Einstein radius, $R_E$.\n",
    "\n",
    "The Einstein radius in angular units is $ R_E = \\sqrt{ \\frac{4 G m}{c^2} \\frac{D_{ls}}{D_l D_s} } = \\sqrt{ 2 R_{sh} \\frac{D_{ls}}{D_l D_s} }$ where $m$ is the mass of the lens and $R_{sh}$ is the Schwarzschild radius of the lens.  $D_{ls}$ is the radial distance between the lens and the source star, $D_l$ is the distance from us to the lens, and $D_s$ is the distance from us to the source.\n",
    "\n",
    "The Einstein crossing time is \n",
    "\n",
    "$t_E = \\frac{2R_E}{v_\\perp}$ where $v_\\perp$ is the velocity of the lens transverse to our line of sight relative to the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pa\n",
    "from math import erf\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the simplifications that :\n",
    "\n",
    "* the density of lenses is constant between the observer and sources\n",
    "* the lenses' velocities are Gaussian distributed with zero mean\n",
    "* all the lenses have the same mass\n",
    "\n",
    "the event rate, $\\Gamma$, as a function of Einstein times can be found to be\n",
    "\n",
    "$\\frac{d\\Gamma}{dt_E} = \\frac{\\sigma^2 D_s \\eta}{4 t_o} \\left( \\frac{t_o}{t_E} \\right)^4 \\left[  \\pi \\left( \\left( \\frac{t_o}{t_E} \\right)^4  + 8\\left( \\frac{t_o}{t_E} \\right)^2 + 3 \\right) \\exp\\left[ - \\frac{1}{8}  \\left( \\frac{t_o}{t_E} \\right)^2 \\right] {\\rm erf}\\left(  \\left( \\frac{t_o}{3t_E} \\right)^{3/2} \\right) - \\frac{ \\left( \\frac{t_o}{t_E} \\right)^2 +12 }{ \\left( \\frac{t_o}{t_E} \\right)^4} \\right]$\n",
    "\n",
    "\n",
    "\n",
    "The charactoristic timescale is $t_o = \\frac{2 R_{sh} D_s}{\\sigma^2}$ where $\\sigma^2$ is the velocity dispersion of the lenses.  $\\eta$ is the number density of lenses.  We will not be concerned with measuring the normalization here.  We will only seek to recover $t_o$.  Since we can estimate $D_s$ and $\\sigma^2$ from other sources, this would be a measure of the lenses' mass.\n",
    "\n",
    "1) Code up the Einstein time distribution.  The normalization needs to be calculated numerically.  Calculate it by integrating over $t_e$ with quad().  Keep the normalization constant out of the function definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "norm = 1\n",
    "def dGammdt(te,to) :\n",
    "    if te<0.1*to :  # this avoids some numerical problems\n",
    "        return 0\n",
    "    t = to/te\n",
    "    return  ...\n",
    "\n",
    "tes = np.linspace(0.01,1,100)\n",
    "\n",
    "norm = \n",
    "\n",
    "dGammdt_v = np.vectorize(dGammdt)  # this allows a vector input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Plot the normalized $t_E$ distribution for $t_o=50$ and $t_o=80$ on the same plot with labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) By integrating your probability distribution, calculate the cumulative distribution function of $t_E$ for $t_o=60$, $F(t_E|t_o)$ and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = np.empty_like(tes)\n",
    "for i,t in enumerate(tes) :\n",
    "    cdf[i] = ....\n",
    "\n",
    "plt.plot(tes*to,cdf)\n",
    "plt.xlabel(r'$t_E$')\n",
    "plt.ylabel(r'CDF($t_E| t_O$')\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Calculate approximately what the value of $t_o$ should be for events in the galactic bulge.  Use $D_s=8$ kpc, $\\sigma = 200$ km/s and lens mass 1 $M_{sun}$.  To do this, you might find the following modules in astropy useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import astropy.constants as const\n",
    "from astropy import units \n",
    "\n",
    "# some examples\n",
    "print(const.M_sun)\n",
    "print(const.M_sun/const.c**2)\n",
    "print(const.M_sun*const.G/const.c**2)\n",
    "print('10 days in seconds = ',10*units.day.to('s')*units.s)\n",
    "\n",
    "\n",
    "to = ...\n",
    "\n",
    "print(to.value,'days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Read in the data and make a histogram of both the $t_E$'s and the $\\Delta t$'s on the same plot.  Make the histograms transparent so you can see the overlapping regions (hint: use the alpha keyword)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pa.read_csv('microlensing_events.csv')\n",
    "te_ob = ...\n",
    "t_ob = ...\n",
    "\n",
    ".\n",
    ".\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Write a negative log-likelihood function for the $t_E$ data.   Use it to plot the likelihood as a function of $t_o$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loglike(to) :\n",
    "    return ...\n",
    "\n",
    "tos = np.linspace(50,100,100)\n",
    "ll_noselection = np.empty_like(tos)\n",
    "for i,t in enumerate(tos) :\n",
    "    \n",
    "\n",
    "plt.plot(...)\n",
    "plt.xlabel(r'$t_o$')\n",
    "plt.ylabel(r'$L(t_E | t_o)$')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Find the maximum likelihood solution for $t_o$ using scipy.optimize.minimize(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize \n",
    "\n",
    "...\n",
    "\n",
    "print('maximum likelihood t_o = ',best.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Einstein time, $t_E$, is measurable from the shape of the light curve for each event, but it is not the actual length of the microlensing event.  It is the time it would take for the source to travel 2 $R_E$ .  The actual duration of the event is the time the source spends *within* one $R_E$ of the lens.  This diagram might make it clearer.\n",
    "\n",
    "<img src=\"einstein_time.png\" alt=\"t_e\" class=\"bg-primary\" width=\"400px\">\n",
    "\n",
    "The two times are equal only if the path of the source passes directly through the lens.\n",
    "\n",
    "Since the impact parameter is uniformly distributed, the distribution of times is :\n",
    "\n",
    "$p(\\Delta t|t_E) =  \\left\\{\\begin{array}{cc}\n",
    "\\frac{1}{t_E}\\frac{\\Delta t}{\\sqrt{t_E^2 - \\Delta t^2}} & \\Delta t< t_E \\\\\n",
    "0 & \\Delta t > t_E\n",
    "\\end{array} \\right.\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Write functions that give pdf $p(\\Delta t | t_E)$, the cdf $F(\\Delta t | t_E)$ and the quantile function $Q(u | t_E)$.  These can all be found analytically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_te(t,te) :\n",
    "    if(t>=te or t<0) :\n",
    "        return 0\n",
    "    return ...\n",
    "\n",
    "## cumulative F(t|te)\n",
    "def cdft_te(t,te) :\n",
    "    if(t > te) :\n",
    "        return ..\n",
    "    return ...\n",
    "\n",
    "## quantile function Q(u|te)\n",
    "def quantile_te(u,te) :\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Find $p(\\Delta t|to)$ by integrating over $t_E$ for $t_o=60$.  Remember the product rule!  This must be integrated for each $t_E$.\n",
    "\n",
    "Plot both $p(t_E|t_o)$ again and $p(\\Delta t|to)$ in the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to=60\n",
    "## make the function p(te,t|to)\n",
    "def pte(te,t,to) :\n",
    "    return ...\n",
    "\n",
    "\n",
    "p = np.empty_like(tes)\n",
    "for i,t in enumerate(tes) :\n",
    "    p[i] = ... # integrate over te\n",
    "\n",
    "...\n",
    "plt.plot(tes*to,...label=r'$p(\\Delta t|t_o)$')\n",
    "plt.plot(tes*to,...label=r'$p(t_E|t_o)$')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(r'$t_E ~, ~t$')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Events that are too long or short cannot be detected because of the observation cadence and the duration of the monitoring campaign.  We will simplify these restrictions by saying that events with $\\Delta t < t_{min}$ or  $\\Delta t > t_{max}$ are not observable in our data set.\n",
    "\n",
    "9) Now construct the likelihood that takes into account the *selection*.  The likelihood for one event with the selection function $S(\\Delta t)$ is:\n",
    "\n",
    "$ L(t,t_E | t_o) = \\frac{p(t|t_E,t_o)p(t_E|t_o)S(t)}{\\int_0^\\infty dt_E p(t_E|to) \\int_0^\\infty dt p(t|t_E) S(t) } \n",
    "= \\frac{p(t|t_E)p(t_E|t_o)}{\\int_0^\\infty dt_E p(t_E|to) \\left[  F(t_{max}|t_E) - F(t_{min}|t_E) \\right]} $\n",
    "\n",
    "$t$ here is $\\Delta t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denominator of above\n",
    "def dnormdte(te,to,tmin,tmax) :\n",
    "    return ...\n",
    "\n",
    "def lnL(to,tmin,tmax) :\n",
    "   norm = quad( ...  )\n",
    "   output = ....\n",
    "   for i,te in enumerate(te_ob) :\n",
    "       ....\n",
    "       output += np.log( .... )\n",
    "   ...\n",
    "    return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Using $t_{min} = 10$ days and $t_{max} = 60$ days, loop through tos to make a vector of the likelihood as a function of $t_o$.  This may take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin=10\n",
    "tmax=60\n",
    "ll = np.empty_like(tos)\n",
    "\n",
    "for i,to in enumerate(tos) :\n",
    "    ll[i] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Make a plot of the posterior found before using only $t_E$'s and no selection, and the posterior with selection taken into account.  Normalize these numerically using scipy.integrate.trapz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import trapz\n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(r'$t_o$')\n",
    "plt.ylabel(r'$L(t_E | t_o)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12)  Find the maximum likelihood value for $t_o$ with the selection effects.  Find this by finding the location of the maximum in the plot you just made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ML to = \",...)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Find the mean and variance of the posterior using numerical integration of the table already created  ( use scipy.integrate.trapz() )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".\n",
    ".\n",
    ".\n",
    "print('<to> = ', ... ,' +/- ', ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Calculate the mass of the lenses for the maximum likelihood solution for $t_o$ taking $D_s=8$ kpc, $\\sigma = 200$ km/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('lens mass = ', ,' +/- ',...,' Msun' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual case is a bit more complicated.  This is a calculation of the OGLE microlensing survey's true selection function as function of $t_E$ and the the closest approach in units of $R_E$ (Peel & Dennison, 2006).\n",
    "\n",
    "<img src=\"OGLE-detection-efficiency.png\" alt=\"t_e\" class=\"bg-primary\" width=\"400px\">\n",
    "\n",
    " This is calculated by creating fake events and seeing what fraction of them are detected. This is calculated by running an event detection algorithm on simulated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
