{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tutorial 3 - Measuring a Spectral Line by Bayesian Parameter Estimation**\n",
    "\n",
    "In this tutorial you will measure the strength and width of a spectral line \n",
    "using a Bayesian method.\n",
    "\n",
    "\n",
    "1) Read in the data from the file tut_03_data.csv.  There are three \n",
    "columns: wavelength, flux and sigma.  Sigma is the known standard deviation \n",
    "of the flux in each pixel.  Plot the spectrum using matplotlib.pyplot.errorbar()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pa\n",
    "\n",
    "df = pa.read_csv('tut_03_data.csv')\n",
    ".\n",
    ".\n",
    ".\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) First we need to subtract off the continuum. We know that there is a line centred around $\\lambda \\simeq 23$.  Take the part of the spectrum with $\\lambda > 45$ which should just be background.  Assuming the noise is Gaussian and uncorrelated.   Using a uniform prior on the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.optimize as opt\n",
    "\n",
    "## Separate out the background dominated region of the spectrum, \n",
    "##  wavelength > 45,  Make vectors of the flux, wavelength and \n",
    "## sigma for these pixels.\n",
    "\n",
    "df_bk_pixels = \n",
    "\n",
    "## Make a function that takes the background level b and \n",
    "## returns the log-likelihood calculated from the data \n",
    "## in the vectors above.  The pixels are statistically independent.\n",
    "## You can use the df_bk_pixels dataframe made above inside the function\n",
    "## you define.\n",
    "\n",
    "def loglike(b):\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "\n",
    "## Make an array of possible background values.  Call \n",
    "## it \"background\".\n",
    "## To find the right range it is sometimes useful to \n",
    "## plot the log-likelihood over different ranges until \n",
    "## you find the maximum and you are sure the likelihood \n",
    "## is zero at both edges of the range.\n",
    "\n",
    "db = 0.001 ## resolution in background\n",
    "background = np.arange(-0.1,0.15,db)\n",
    "\n",
    "## Calculate the likelihood at each of these background values\n",
    "## using the function you have made.\n",
    "\n",
    "likelihood = np.empty(len(background))\n",
    "for i,b in enumerate(background) :\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "\n",
    "## Normalize this numerically by summing the \n",
    "## likelihood array to get the posterior distribution \n",
    "## for the background.\n",
    "## You should look at the plot and make sure that\n",
    "## the sum is a good approximation of the integral, i.e. \n",
    "## the spacing in the parameter is small enough to make the \n",
    "## curve smooth and the range is large enough.\n",
    "   \n",
    "## plot posterior for background normalized numerically\n",
    "\n",
    "plt.xlabel('background')\n",
    "plt.ylabel('probability')\n",
    "plt.title('posterior')\n",
    "plt.show()\n",
    "\n",
    "print 'Posterior at edges of parameter space: ',posterior[0],posterior[-1]\n",
    "\n",
    "## Find maximum of posterior and the variance numerically.  \n",
    "## Use opt.fmin()\n",
    "## The integrals can be made into sums.\n",
    ".\n",
    ".\n",
    ".\n",
    "print 'The maximum likelihood background is :',bmax\n",
    "print 'The average of posterior  :',bave\n",
    "print 'The standard deviation of the posterior  :',np.sqrt(variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Now lets fit the line.  Assume the line has the profile\n",
    "\n",
    "$ f(\\lambda) = A \\exp\\left[- \\left( \\frac{(\\lambda - \\lambda_o)}{\\Delta\\lambda }\\right)^2 \\right] $\n",
    "\n",
    "We want to find the parameters $A$, $\\lambda_o$, $\\Delta\\lambda$ and the background.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "## Write a function for the line profile that takes \n",
    "## the wavelength, A, center of line, lo, and the width \n",
    "## of the line dl.\n",
    "def line_profile(l,A,lo,dl):\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "\n",
    "## Write a function that takes the parameters \n",
    "## A,lo,dl,b and returns the log-likelihood for \n",
    "## the data.  The function should have the signature \n",
    "## def loglike(p): where p[0]=A, p[1]=lo, p[2]=dl and p[3]=b\n",
    "## You should use the original dataframe for the data with \n",
    "## the full range of wavelength.\n",
    "def loglike(p):\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    \n",
    "## Find the maximum likelihood values for the parameters using \n",
    "## the whole data set.  Use the library function \n",
    "## scipy.optimize.minimize() to do this. Note that what  \n",
    "## this function returns is a structure with more than just the solution.\n",
    "## Read the documentation for this function before starting.  You will\n",
    "## need to make a guess to start the minimization.  Make these \n",
    "## guesses from the plot of the data.  \n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "print('maximum likelihood solution : ',maxlikelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4) Plot the best fit model over the plot of the data made in \n",
    "## part 1).  Use your line_profile() function.\n",
    "\n",
    "\n",
    "plt.xlabel(r'$\\lambda$')\n",
    "plt.ylabel('flux')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Set all the parameters to their maximum likelihood values except the line strength $A$.  Make a plot of the **conditional posterior** for $A$ near its maximum likelihood value with uniform and Jaffreys priors on $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Aarray = ...\n",
    "\n",
    "posterior = np.empty(len(Aarray))\n",
    "for i,A in enumerate(Aarray):\n",
    "    .\n",
    "    .\n",
    "\n",
    "## normalize the posterior\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "plt.plot(Aarray,posterior,label='uniform prior')\n",
    "plt.plot(Aarray,posterior,label='Jeffreys prior')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('A')\n",
    "plt.show()\n",
    "\n",
    "## Doee the choice of prior change the result significantly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Make a 2D map of the conditional posterior as a function of $A$ and $\\Delta \\lambda$ at the maximum likelihood values of the other parameters.  Do this by making a grid of $A$ and $\\Delta \\lambda$ values and using matplotlib.pyplot.contour().  Put the proper labels on the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dlarray = .....\n",
    "Aarray = ...\n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "## this is very useful for making 2D plots. X and Y are 2D arrays.\n",
    "X, Y = np.meshgrid(dlarray, Aarray)\n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "plt.xlabel('line width')\n",
    "plt.ylabel('line strength')\n",
    "plt.title(\"conditional posterior\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Write a function that takes values for $A$ and $\\Delta \\lambda$ and returns the \n",
    "posterior **marginalized** over $\\lambda_o$.  Use scipy.integrate.quad() to do the \n",
    "integration.  You will need to make a new \"posterior\" function with the correct \n",
    "order of input parameters to use this function.  Use the maximum likelihood value for the background from part 2).  You might want to reduce the resolution of the grid to reduce the run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "# this reorders the parameters\n",
    "def posterior(lo,A,dl,b):\n",
    "    return np.exp(-loglike(np.array([A,lo,dl,b])))\n",
    "    #def loglike(A,lo,dl,b):\n",
    "\n",
    "def marginal_posterior(A,dl):\n",
    "    ## use quad to integrate over lo only using the arg option\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "plt.xlabel('line width')\n",
    "plt.ylabel('line strength')\n",
    "plt.title(\"marginal posterior\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Sum the 2D array from 7) to find the 1D marginalized posteriors for both \n",
    "$\\Delta\\lambda$ and $A$.  This is a numerical marginalization which can be done by simply summing along each of the axes.  The sum approximates an integral over the parameter.\n",
    "\n",
    "Plot both marginal distributions.  If these are not smooth, you haven't used enough points in parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    ".\n",
    ".\n",
    ".\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Find the mean and variance for $\\Delta\\lambda$ and the $A$ using the map of the marginalized posterior found above, the X and Y arrays from above, and the numpy.sum() function.  Each of these will be marginalized over all other variables except the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".\n",
    ".\n",
    ".\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#  This function finds the level for a contour that contains \n",
    "#  a fixed fraction of the total sum of pixels (or voxels).\n",
    "#  Understand it. Run this box so that it is defined\n",
    "#########################################\n",
    "def find_level(posterior,fraction) :\n",
    "    tot = np.sum(posterior)\n",
    "    max = np.max(posterior)\n",
    "    min = np.min(posterior)\n",
    "\n",
    "    ## initialize level to halfway between max and min\n",
    "    level = 0.5*(max + min) \n",
    "    ## initialize fraction for this level\n",
    "    frac = np.sum( posterior[ posterior >= level ]  )/tot\n",
    "    ## initialize resolution = +/- smallest pixel as fraction of total\n",
    "    res = np.min( posterior[ posterior >= level ]  )/tot\n",
    "\n",
    "    ## iterate until frac is within res of the input fraction\n",
    "    while( abs(frac - fraction) > res  ) :\n",
    "        \n",
    "        ## update max or min\n",
    "        if( frac > fraction) :\n",
    "            min = level\n",
    "        else :\n",
    "            max = level\n",
    "        \n",
    "        ## update level by bisecting \n",
    "        level = 0.5*(max + min)\n",
    "        \n",
    "        ## update frac and res    \n",
    "        frac = np.sum( posterior[ posterior >= level ] )/tot\n",
    "        res = np.min( posterior[ posterior >= level ]  )/tot\n",
    "\n",
    "    ## output the level and its actual fraction\n",
    "    return level,frac\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Using the function above, find the 68% and 95% confidence regions for $A$ and $\\Delta\\lambda$ and make a 2D contour plot of these levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
